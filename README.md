# Name of team members
1:- Pranay Joshi <br>
2:- Gaurav Shrivastava <br>
3:- Kavya Gupta <br>
4:- Priyanshu Sethi <br>

# Purpose of project
The purpose of this project is to revolutionize music recommendation systems by integrating neuroscience and artificial intelligence to create playlists that respond to real-time emotional states. Unlike traditional recommendation models that rely on listening history and genre preferences, *Mind Beats* leverages Brain-Computer Interface (BCI) technology to analyze EEG signals and determine a user's mood with high accuracy. By doing so, it aims to break the restrictive feedback loops of conventional algorithms and instead offer a deeply personalized listening experience that enhances positive emotions and alleviates negative ones. This innovation not only redefines how music is consumed but also explores its potential as a tool for emotional well-being, paving the way for future advancements in neuro-adaptive technology.

# Tools utilized
Streamlit, OpenAI, Muse

# Problem and how you overcame
One of the biggest challenges was accurately interpreting EEG signals and mapping them to emotional states given our lack of experience with neuroscience. We spent a lot of time reading and researching to accurately understand EEG Signals and overcome this challenge.

# Credits
OpenAI, Muse

## Setup

### Installation
* ```git clone https://github.com/pranayjoshi/mind_music.git```
* ```cd mind_music```
* ```pip install -r requirements.txt```
* ```streamlit run emotionprediction.py```

### Git commands
* ```git add .```
* ```git commit -m "<your-text>"```
* ```git push```

[Check out our Mind Beats project announcement on LinkedIn](https://www.linkedin.com/posts/pranay-joshi-_hackathon-ai-bci-activity-7294828653262102530-8nG-?utm_source=share&utm_medium=member_desktop&rcm=ACoAACv4_50BjQghzitL37otbIlcv3GVlCxaiCA)
